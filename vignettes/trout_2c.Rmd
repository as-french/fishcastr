---
title: "An example of seasonal forecast development for anadromous brown trout smolts: Part II of IV"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEncoding{UTF-8}
  %\VignetteIndexEntry{An example of seasonal forecast development for anadromous brown trout smolts: Part II of IV}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# INTRODUCTION

This document outlines the calibration and checking of the correlative models for anadromous brown trout (*Salmo trutta*) smolts presented in the accompanying manuscript. Specifically, this vignette describes glmmTMB model structure specification, fitting and checking. A separate vignette, "trout_1abc_2ab", describes the model chain elements and derivations of model explanatory variables such as `fishcastr::data_Feeagh_discharge`.

## (2c) Model fish counts

## Calculate predictors

Prior to fitting glmmTMB models, we pre-processed the raw and model derived catchment environmental data included in `fishcastr`. Pre-processing steps included log transformation of positive skewed predictors (moonlight exposure, discharge and migration preparedness). We included both the log transformed and non-transformed data of these three "likely candidates" in the initial modelling dataset, as it was not clear form the outset whether transformations would improve statistical fit and or computation of the fitting procedure. The inclusion of log transformed vs. non-transformed variables varied among species.

```{r calculate_predictors,eval = FALSE}
# ---------------------------------------------------------------------------------------------------------- #
# IMPORT BIAS ADJUSTED METEOROLOGICAL DATA -----
# ---------------------------------------------------------------------------------------------------------- #
data_ERA5_1979_2019_Jan_bc <- fishcastr::convert_grid_to_dataframe(grid_obj = fishcastr::grid_ERA5_1979_2019_Jan_bc)[,-2]
names(data_ERA5_1979_2019_Jan_bc)[which(names(data_ERA5_1979_2019_Jan_bc) == "dates1")] <- "date"

# ---------------------------------------------------------------------------------------------------------- #
# RUN AIR TO WATER TEMP MODEL -----
# ---------------------------------------------------------------------------------------------------------- #
data_water_temp <- data.frame(
  "date" = data_ERA5_1979_2019_Jan_bc$date,
  "Tw_mod" = fishcastr::air_to_water_model(
    Ta = data_ERA5_1979_2019_Jan_bc$tas,
    Yday = lubridate::yday(data_ERA5_1979_2019_Jan_bc$date),
    A = fishcastr::air_to_water_Feeagh_params_ERA5_bcc$A,
    ac = fishcastr::air_to_water_Feeagh_params_ERA5_bcc$ac,
    b = fishcastr::air_to_water_Feeagh_params_ERA5_bcc$b,
    B = fishcastr::air_to_water_Feeagh_params_ERA5_bcc$B
  )
)

# ---------------------------------------------------------------------------------------------------------- #
# RUN HYDROLOGIC MODEL ----
# ---------------------------------------------------------------------------------------------------------- #
data_discharge <- fishcastr::hydrologic_model(met_data = data_ERA5_1979_2019_Jan_bc[,c("date","pr","petH")] ,
                                              warm_up_dates_range = c(as.Date("1979-01-01"),
                                                                     as.Date("1980-12-20")),
                                              run_dates_range = c(as.Date("1980-12-21"),
                                                                 as.Date("2019-01-31")),
                                              GR4J_params = as.numeric(fishcastr::GR4J_Burr_params_ERA5_bcc),
                                              log_transform = FALSE)

ln_data_discharge <- data.frame("date" = data_discharge$date,
                                "ln_discharge" = log(data_discharge$discharge))

# ---------------------------------------------------------------------------------------------------------- #
# ESTIMATE MIGRATION PREPAREDNESS ----
# ---------------------------------------------------------------------------------------------------------- #

# stratify forecast years and retain photoperiod
data_stsmolt_forecast_years <- fishcastr::bio_year_photoper(dates = data_water_temp$date,
                                                           latitude = 53.932458,
                                                           longitude = -9.575556,
                                                           retain_photoper = TRUE,
                                                           start_previous_year = TRUE,
                                                           shortest_day = TRUE,
                                                           yday_head = "salmonid_yday",
                                                           bio_year_head = "salmonid_year")

# calculate photoperiod weighted degree days from specified solstice dates
pwdds <- fishcastr::convert_stratified_census_data_to_model_warmup_list(
  water_temp = data_water_temp$Tw_mod,
  photoper = data_stsmolt_forecast_years$photoper,
  forecast_years = data_stsmolt_forecast_years$salmonid_year,
  forecast_yday = data_stsmolt_forecast_years$salmonid_yday,
  dates = data_stsmolt_forecast_years$date,
  no_years_warmup = 0,
  delete_op_year = FALSE
)

# convert photoperiod weighted degree days to proxy preparedness variable
migration_preparedness <- data.frame("date"= pwdds$date, "migration_prep" =
  fishcastr::exp_mod_Gaussian_resp(
    x = pwdds$weighted_dds_water,
    c = fishcastr::model_physio_expmG_trout$coefs["c"],
    mu_exmg = fishcastr::model_physio_expmG_trout$coefs["mu_exmg"],
    sigma_exmg = fishcastr::model_physio_expmG_trout$coefs["sigma_exmg"],
    lamb = fishcastr::model_physio_expmG_trout$coefs["lamb"]
  ))

ln_migration_preparedness <- data.frame("date"= pwdds$date, "ln_migration_prep" =
  log(migration_preparedness$migration_prep))

# ---------------------------------------------------------------------------------------------------------- #
# ESTIMATE MOONLIGHT EXPOSURE ----
# ---------------------------------------------------------------------------------------------------------- #
data_lunar <- data.frame("date"= migration_preparedness$date,
                         "moonlight_exposure" = fishcastr::lunar_light_exposure(log_result = FALSE, date_of_interest = migration_preparedness$date,
                                                                                lat = 53.932458,
                                                                                lon = -9.575556))
ln_data_lunar <- data.frame("date"= migration_preparedness$date,
                         "ln_moonlight_exposure" = fishcastr::lunar_light_exposure(log_result = TRUE, date_of_interest = migration_preparedness$date,
                                                                                lat = 53.932458,
                                                                                lon = -9.575556))

# -------------------------------------------------------------------------------------------------- #
# ADD DELTA TEMPERATURE ----
# -------------------------------------------------------------------------------------------------- #
Delta_temp <- data.frame("date" = data_water_temp$date,
                         "Delta_temp" = fishcastr::delta_var(y = data_water_temp$Tw_mod,
                                                             react_time = 20))

# -------------------------------------------------------------------------------------------------- #
# ADD DELTA PHOTOPERIOD ----
# -------------------------------------------------------------------------------------------------- #
Delta_Photo <- data.frame("date" = data_stsmolt_forecast_years$date,
                          "Delta_photo" = fishcastr::delta_var(y = data_stsmolt_forecast_years$photoper,
                                                               react_time = 1))

# ---------------------------------------------------------------------------------------------------------- #
# IMPORT AND APPEND COUNT DATA TO FORECAST YEARS ENVIRONMENTAL DATA ----
# ---------------------------------------------------------------------------------------------------------- #
data_stsmolt <- fishcastr::data_stsmolt

# Use Reduce function instead of merge...
data_stsmolt_enviro_1981_2019 <- Reduce(function(x,y) merge(x,y,by="date"),
                                       list(data_stsmolt,
                                            data_stsmolt_forecast_years,
                                            data_water_temp,
                                            data_discharge,
                                            ln_data_discharge,
                                            migration_preparedness,
                                            ln_migration_preparedness,
                                            data_lunar,
                                            ln_data_lunar,
                                            Delta_temp,
                                            Delta_Photo))

dirName <- paste0(system.file("vignettes", package = "fishcastr"),"/vignette_data/")
dir.create(dirName, showWarnings = TRUE, mode = "0777")

 saveRDS(data_stsmolt_enviro_1981_2019, file = paste0(dirName,"data_stsmolt_enviro_1981_2019.rds"))
 rm(list = ls(all.names = TRUE))
 invisible(gc())
```

## Refine model structure based on fit to historic data and validate

Prior to model fitting, we centred and scaled all explanatory variables with the aim of mitigating computational problems with model convergence (see [here](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html) and [here](https://cran.r-project.org/web/packages/glmmTMB/vignettes/troubleshooting.html)).

```{r model_trout_counts_II_of_IV_fit_model,eval = FALSE}
# ---------------------------------------------------------------------------------------------------------- #
# LOAD COUNT AND PREDICTOR DATA ----
# ---------------------------------------------------------------------------------------------------------- #
data_stsmolt_enviro_1981_2019 <- readRDS(paste0(system.file("vignettes",
                                                    package = "fishcastr"),
                                               "/vignette_data/data_stsmolt_enviro_1981_2019.rds"))

# -------------------------------------------------------------------------------------------------- #
# SUBSET DATA TO 1981 - 1992 TO MAINTAIN OUT OF SAMPLE MODEL VALIDATION OF MODEL STRUCTURE ----
# -------------------------------------------------------------------------------------------------- #
# This step is carried out to reduce the risk of overfitting (model structure)
# to the test set. This does not reduce the risk of over-parameterizing the
# model for these data; rather, the aim is stop model re-structuring (relative
# to full model containing no predictor transformations) at the first point at
# which a statistically acceptable model is identified. Priorities for
# acceptability/validation:
# (i) limited set of plausible predictors and no more complex than three-way
# interactions (choice of predictors is set form the outset based on literature);
# (ii) linearity (predictors are transformed to remove patterns in residual vs.
# individual predictor plots);
# (iii) residual dispersion (over/under dispersion - important to get this right
# as using model simulations (and predictions) for forecasts) - here we move
# beyond Poisson to choose a conditional distribution of the response (daily
# count), e.g., negative binomial type I or II, or generalised Poisson (as these
# are implemented in glmmTMB);
# (iv) independence of errors (check for residual autocorrelation within and
# among years using ACF);
# (v) influential groups - check using plots of Cook's distance and dfbetas.
# After model checking as above, we want to assess out of sample predictive
# performance. We use leave-one year out cross validation to refit the model
# sequentially for all years between 1981 to 2019, and we plot the model
# simulations for each year on top of observations to visually assess
# inconsistencies between simulated and observed data. ASSUMPTION - by using
# leave-one-year-out model fitting, we assume that the structure of model
# (derived from 1981 - 1992 fit) is consistent across time series, although it
# is possible that parameters (i.e., associations between counts and predictors
# may vary through time)).
# -------------------------------------------------------------------------------------------------- #

# -------------------------------------------------------------------------------------------------- #
# SUBSET DATA 1981 - 1992 ----
# -------------------------------------------------------------------------------------------------- #
min_1981 <- min(data_stsmolt_enviro_1981_2019$date[data_stsmolt_enviro_1981_2019$salmonid_year == 1981])
max_1992 <- max(data_stsmolt_enviro_1981_2019$date[data_stsmolt_enviro_1981_2019$salmonid_year == 1992])

Train_data <- subset(data_stsmolt_enviro_1981_2019, select = c(date,
                                                              stsmolt,
                                                              salmonid_year,
                                                              salmonid_yday,
                                                              migration_prep,
                                                              ln_migration_prep,
                                                              moonlight_exposure,
                                                              ln_moonlight_exposure,
                                                              discharge,
                                                              ln_discharge,
                                                              Delta_temp,
                                                              Delta_photo,
                                                              photoper,
                                                              Tw_mod),
                     subset = data.table::between(data_stsmolt_enviro_1981_2019$date,
                                                  lower = min_1981,
                                                  upper = max_1992))

# -------------------------------------------------------------------------------------------------- #
# SCALE PREDICTORS AND CENTRE THOSE THAT HAVE NON-MEANINGFUL ZEROS (Here, just scale...) ----
# -------------------------------------------------------------------------------------------------- #
library(caret)
pP_params_train <- caret::preProcess(Train_data[,4:ncol(Train_data)], method = c("center","scale"))
Train_data_scaled_centred_train <- predict(object = pP_params_train, newdata = Train_data)

#dirName <- paste0(system.file("vignettes", package = "fishcastr"), "/vignette_data/")
#saveRDS(Train_data_scaled_centred_train, file = paste0(dirName,"Train_data_scaled_centred_train.rds"))

# -------------------------------------------------------------------------------------------------- #
# FIT MODELS ----
# -------------------------------------------------------------------------------------------------- #

# # model 1 all three way interactions
 library(glmmTMB)
#  m1 <- glmmTMB::glmmTMB(stsmolt ~ (discharge + migration_prep + moonlight_exposure + Tw_mod)^3 + (1|salmonid_year),
#                                        poisson(link = "log"),
#                                        data=Train_data_scaled_centred_train)
#  simulatedResiduals_m1 <- DHARMa::simulateResiduals(m1)
#  
#  par(mfrow = c(2,1))
#  DHARMa::testDispersion(simulatedResiduals_m1)
#  DHARMa::testZeroInflation(simulatedResiduals_m1)
# # #overdispersed and zero inflated and non-linearities
# # 
# # # -------------------------------------------------------------------------------------------------- #
# # # model 2 log of migration_prep
#  m2 <- glmmTMB::glmmTMB(stsmolt ~ (discharge+ln_migration_prep + moonlight_exposure + Tw_mod)^3 + (1|salmonid_year),
#                                        poisson(link = "log"),
#                                        data=Train_data_scaled_centred_train)
#  simulatedResiduals_m2 <- DHARMa::simulateResiduals(m2)
#  
#  par(mfrow = c(2,1))
#  DHARMa::testDispersion(simulatedResiduals_m2)
#  DHARMa::testZeroInflation(simulatedResiduals_m2)
# # # now both zero inf and overdispersion
# 
# # # -------------------------------------------------------------------------------------------------- #
# # # model 2 log of migration_prep and discharge
#  m2 <- glmmTMB::glmmTMB(stsmolt ~ (ln_discharge+ln_migration_prep + moonlight_exposure + Tw_mod)^3 + (1|salmonid_year),
#                                        poisson(link = "log"),
#                                        data=Train_data_scaled_centred_train)
#  simulatedResiduals_m2 <- DHARMa::simulateResiduals(m2)
#  
#  par(mfrow = c(2,1))
#  DHARMa::testDispersion(simulatedResiduals_m2)
#  DHARMa::testZeroInflation(simulatedResiduals_m2)
# # # still both zero inf and overdispersion
#  
#  # # -------------------------------------------------------------------------------------------------- #
# # # model 2 log of migration_prep and discharge and genpois
#  m2 <- glmmTMB::glmmTMB(stsmolt ~ (ln_discharge+ln_migration_prep + moonlight_exposure + Tw_mod)^3 + (1|salmonid_year),
#                                        genpois(link = "log"),
#                                        data=Train_data_scaled_centred_train)
#  simulatedResiduals_m2 <- DHARMa::simulateResiduals(m2)
#  
#  par(mfrow = c(2,1))
#  DHARMa::testDispersion(simulatedResiduals_m2)
#  DHARMa::testZeroInflation(simulatedResiduals_m2)
# # # better but slight overdispersion and non linear Tw_mod
 
# -------------------------------------------------------------------------------------------------- #
# model 3 all two way interactions and three way interactions involving ln_discharge ln_migration_prep genpois and quadratic temp
m3 <- glmmTMB::glmmTMB(stsmolt ~ (Tw_mod + I(Tw_mod^2))*(ln_discharge+ln_migration_prep + moonlight_exposure)^2 + (ln_discharge+ln_migration_prep + moonlight_exposure)^3 + (1|salmonid_year),
                                      genpois(link = "log"),
                                      data=Train_data_scaled_centred_train)
simulatedResiduals_m3 <- DHARMa::simulateResiduals(m3)
#par(mfrow = c(2,1))
#DHARMa::testDispersion(simulatedResiduals_m3)
#DHARMa::testZeroInflation(simulatedResiduals_m3)
#still slight overdispersion and some pattern in ln_migration_prep vs resid, but not major

# model 3b check structure using poly
m3b <- glmmTMB::glmmTMB(stsmolt ~ (ln_discharge+ln_migration_prep + moonlight_exposure + poly(Tw_mod,2,raw = TRUE))^3  + (1|salmonid_year),
                                      genpois(link = "log"),
                                      data=Train_data_scaled_centred_train)
simulatedResiduals_m3b <- DHARMa::simulateResiduals(m3b)

#par(mfrow = c(2,1))
#DHARMa::testDispersion(simulatedResiduals_m3b)
#DHARMa::testZeroInflation(simulatedResiduals_m3b)

# check effectively identical
effs <- (glmmTMB::fixef(m3))
effsb <- (glmmTMB::fixef(m3b))
param_diffs <- as.vector((signif(sort(effs$cond),3)) - signif(sort(effsb$cond),3))
# do the models produce effectively identical parameter estimates?
ifelse(all(param_diffs <= 0.00005), TRUE,FALSE)

# -------------------------------------------------------------------------------------------------- #
# MODEL VALIDATION PLOTS FOR CHOSEN MODEL ------
# -------------------------------------------------------------------------------------------------- #
mod_check <- simulatedResiduals_m3
# Create vignette sub directories ------------------------------------------------------
dirName <- paste0(system.file("vignettes", package = "fishcastr"),"/vignette_figures/")
dir.create(dirName, showWarnings = TRUE, mode = "0777")

dirName <- paste0(system.file("vignettes", package = "fishcastr"),"/vignette_figures/FigS5/")
dir.create(dirName, showWarnings = TRUE, mode = "0777")

dirName <- paste0(system.file("vignettes", package = "fishcastr"),"/vignette_figures/FigS5/trout/")
dir.create(dirName, showWarnings = TRUE, mode = "0777")


png(file = paste0(dirName,'FigS5a.png'), width=2100, height=1200, res=300)
plot(mod_check, rank = T, smoothScatter = FALSE, quantreg = TRUE)
invisible(dev.off())

png(file = paste0(dirName,'FigS5b.png'), width=1800, height=2100, res=300)
par(mfrow = c(2,1), oma = c(0,0,0,0), mar = c(4,4,5,4))
# overdispersion
DHARMa::testDispersion(mod_check)
# zero inflation
DHARMa::testZeroInflation(mod_check)
invisible(dev.off())

# -------------------------------------------------------------------------------------------------- #
# NON-LINEARITY VALIDATION PLOTS (IF PATTERNS PRESENT IN FIT VS RESIDUALS) ----
# -------------------------------------------------------------------------------------------------- #
# individual predictors
png(file = paste0(dirName,'FigS5e.png'), width=2500, height=2500, res=300)
par(mfrow = c(2,2), mar = c(3.5,3.5,3.5,0.5),mgp = c(2.5,1,0))
   DHARMa::plotResiduals(form = Train_data_scaled_centred_train$ln_migration_prep,
                         simulationOutput = mod_check,
                         quantreg = T,smoothScatter = FALSE,
                         rank = T, xlab = "ln_migration_prep")
     DHARMa::plotResiduals(form = Train_data_scaled_centred_train$moonlight_exposure,
                         simulationOutput = mod_check,
                         quantreg = T,smoothScatter = FALSE,
                         rank = T, xlab = "moonlight_exposure",)
       DHARMa::plotResiduals(form = Train_data_scaled_centred_train$ln_discharge,
                         simulationOutput = mod_check,
                         quantreg = T,smoothScatter = FALSE,
                         rank = T, xlab = "ln_discharge")
               DHARMa::plotResiduals(form = Train_data_scaled_centred_train$Tw_mod,
                          simulationOutput = mod_check,
                          quantreg = T,smoothScatter = FALSE,
                          rank = T, xlab = "Tw_mod")
invisible(dev.off())

# -------------------------------------------------------------------------------------------------- #
# TEMPORAL AUTOCORRELATION ----
# -------------------------------------------------------------------------------------------------- #
temp_autocorr_plot_data <- data.frame("residssim_date" = Train_data_scaled_centred_train$date,
                                      "residssim" = mod_check$scaledResiduals,
                                      "residssim_bioyear" = Train_data_scaled_centred_train$salmonid_year)

# among years ---
png(file = paste0(dirName,'FigS5c.png'), width=2400, height=1400, res=300)
par(mfrow = c(1,1), oma = c(0,0,0,0), mar = c(4,4,5,4))
DHARMa::plotResiduals(mod_check,
                      Train_data_scaled_centred_train$salmonid_year,
                      asFactor = TRUE, main = "S. trutta")
invisible(dev.off())

# within years -----
temp_auto_within_year <- lapply(unique(temp_autocorr_plot_data$residssim_bioyear),FUN = function(x){
DHARMa::testTemporalAutocorrelation(temp_autocorr_plot_data$residssim[temp_autocorr_plot_data$residssim_bioyear == x],
                                    time = temp_autocorr_plot_data$residssim_date[temp_autocorr_plot_data$residssim_bioyear == x], plot = FALSE)
})

png(file = paste0(dirName,'FigS5d.png'), width=2500, height=2000, res=300)
par(mfrow = c(4,3), mar = c(3.5,4.5,0.5,0.5),mgp = c(2,1,0))
temp_auto_within_year_acf <- lapply(unique(temp_autocorr_plot_data$residssim_bioyear),FUN = function(x){
acf(x = temp_autocorr_plot_data$residssim[temp_autocorr_plot_data$residssim_bioyear == x])
  mtext(text = paste0(x),side = 3,line = -1.5, cex = 0.75, adj = 0.9)
})
invisible(dev.off())

# export model
dirName <- paste0(system.file("vignettes", package = "fishcastr"), "/vignette_data/")
saveRDS(m3, file = paste0(dirName,"m3_trout_historic.rds"))

 rm(list = ls(all.names = TRUE))
 invisible(gc())
```

## Check influence of individual years on model parameters

### Generate influence statistics (dfbeta)

```{r model_trout_counts_II_of_IV_check_influence_I,eval = FALSE}
# -------------------------------------------------------------------------------------------------- #
# INFLUENTIAL YEARS
# see https://cran.r-project.org/web/packages/glmmTMB/vignettes/model_evaluation.pdf
# -------------------------------------------------------------------------------------------------- #
library(glmmTMB)

Train_data_scaled_centred_train <- readRDS(paste0(system.file("vignettes",
                                 package = "fishcastr"),
                     "/vignette_data/Train_data_scaled_centred_train.rds"))

#chosen_model <- m3

chosen_model <- readRDS(paste0(system.file("vignettes",
                                 package = "fishcastr"),
                     "/vignette_data/m3_trout_historic.rds"))

source(system.file("other_methods","influence_mixed.R", package="glmmTMB"))
system.time(chosen_model_influence <- influence_mixed(chosen_model,
                                                      groups = "salmonid_year",
                                                      component = "cond"))
#66.52 /60# 1.1 mins

dirName <- paste0(system.file("vignettes", package = "fishcastr"), "/vignette_data/")
saveRDS(chosen_model_influence, file = paste0(dirName,"chosen_model_influence.rds"))
```

### Compute Cook's D from influence statistics

```{r model_trout_counts_II_of_IV_check_influence_II,eval = FALSE}
library(glmmTMB)
library(car)

chosen_model_influence <- readRDS(paste0(system.file("vignettes",
                                 package = "fishcastr"),
                     "/vignette_data/chosen_model_influence.rds"))

inf <- as.data.frame(chosen_model_influence[["fixed.effects[-salmonid_year]"]])
inf <- transform(inf,
                 salmonid_year=rownames(inf),
                 cooks=stats::cooks.distance(chosen_model_influence))
inf$ord <- rank(inf$cooks)
```

### Compute influence statistics scaled by standard errors (dfbetas)

```{r model_trout_counts_II_of_IV_check_influence_III,eval = FALSE}
chosen_model_influence <- readRDS(paste0(system.file("vignettes",
                                 package = "fishcastr"),
                     "/vignette_data/chosen_model_influence.rds"))

inf <- as.data.frame(chosen_model_influence[["fixed.effects[-salmonid_year]"]])
inf <- transform(inf,
                 salmonid_year=rownames(inf),
                 cooks=stats::cooks.distance(chosen_model_influence))
inf$ord <- rank(inf$cooks)

inf_full_mod_eff <-as.list(chosen_model_influence[["fixed.effects"]])

# extract standard errors of param estimates excluding higher levels under investigation
year_names <- names(chosen_model_influence[["vcov[-salmonid_year]"]])
serrs_list <- lapply(year_names,FUN = function(x){
  sqrt(diag(chosen_model_influence[["vcov[-salmonid_year]"]][[x]]))
})
serrs <- do.call(rbind,serrs_list)
rownames(serrs) <- year_names

# calculate dfbetas - each value will be positive if the effect with the included level is stronger than without it.
# e.g., the intercept is greater with the inclusion of 1987 data (because 1987 was a high count)
  dfbetas <- inf
for(i in 1:(ncol(inf)-3)){
  dfbetas[,i] = (inf[,i] - inf_full_mod_eff[[i]])/serrs[,i]
}

#for(i in 1:(ncol(inf)-3)){
#  dfbetas[,i] = (inf[,i] - inf_full_mod_eff[[i]])
#}

dfbetas <- transform(dfbetas,
                     salmonid_year=rownames(dfbetas))

dirName <- paste0(system.file("vignettes", package = "fishcastr"), "/vignette_data/")
saveRDS(dfbetas, file = paste0(dirName,"dfbetas.rds"))
```

### Plot dfbetas and Cook's D

```{r model_trout_counts_II_of_IV_check_influence_IV,eval = FALSE}
dfbetas <- readRDS(paste0(system.file("vignettes",
                                 package = "fishcastr"),
                     "/vignette_data/dfbetas.rds"))
#inf_long_sort <- inf_long[with(inf_long, order(inf_long$variable,-inf_long$ord)),]

library(ggplot2)
library(reshape2)

theme_set(theme_bw())
dirName <- paste0(system.file("vignettes", package = "fishcastr"),"/vignette_figures/FigS5/trout/")
png(file = paste0(dirName,'FigS5f.png'), width=7000, height=4000, res=300)
if (require(reshape2)){
  inf_long <- reshape2::melt(dfbetas, id.vars=c("ord","salmonid_year"))
#  inf_long_sort <- inf_long[with(inf_long, order(inf_long$variable,-inf_long$ord)),]
  gg_infl <- (ggplot2::ggplot(inf_long, aes(salmonid_year,value))
              + geom_segment(aes(x=salmonid_year,xend=salmonid_year,y=0,yend=value),colour="black", size = 2)
              + facet_wrap(~variable, scale="free_y")
              + scale_y_continuous(expand=expansion(mult=0.5))
              + geom_text(data=subset(inf_long,
                                       abs(value) > 1),
                           aes(y = value + (0.6 * (value)), label=salmonid_year),
                           vjust=0.0, angle = 90)
              + geom_hline(yintercept=0,linetype = "dashed")
              + theme(axis.text.x = element_text(angle = 90)))
  print(gg_infl)}
invisible(dev.off())
```

## Plot interactions to gauge plausibility of parameter estimates

```{r model_trout_counts_II_of_IV_plot_interactions,eval = FALSE}

library(glmmTMB)
chosen_model <- readRDS(paste0(system.file("vignettes",
                                 package = "fishcastr"),
                     "/vignette_data/m3_trout_historic.rds"))

Train_data_scaled_centred_train <- readRDS(paste0(system.file("vignettes",
                                 package = "fishcastr"),
                     "/vignette_data/Train_data_scaled_centred_train.rds"))

# -------------------------------------------------------------------------------------------------- #
# PLOT ALL TWO AND THREE-WAY INTERACTIONS OF SELECTED MODEL
# -------------------------------------------------------------------------------------------------- #
interactions_list_3 <- list("7" = c("Tw_mod","ln_migration_prep","ln_discharge"),
                          "8" = c("ln_discharge","Tw_mod","moonlight_exposure"),
                          "9" = c("ln_migration_prep","moonlight_exposure","Tw_mod"),
                          "10" = c("moonlight_exposure","ln_discharge","ln_migration_prep"))

# -------------------------------------------------------------------------------------------------- #
# with points
int_plots <- lapply(interactions_list_3,FUN = function(x){
  
  # set x axis lims
  # 75th
  data_75_plus <- Train_data_scaled_centred_train[Train_data_scaled_centred_train[[x[3]]] >= quantile(Train_data_scaled_centred_train[[x[3]]], probs = c((((75+50)/2)/100))),]
xlims75 <- c(range(data_75_plus[[x[1]]]))
  # 50th
  data_50_plus <- Train_data_scaled_centred_train[Train_data_scaled_centred_train[[x[3]]] >= quantile(Train_data_scaled_centred_train[[x[3]]], probs = c((((50+50)/2)/100))),]
xlims50 <- c(range(data_50_plus[[x[1]]]))
  # 75th
  data_25_plus <- Train_data_scaled_centred_train[Train_data_scaled_centred_train[[x[3]]] >= quantile(Train_data_scaled_centred_train[[x[3]]], probs = c((((25+50)/2)/100))),]
xlims25 <- c(range(data_25_plus[[x[1]]]))
# xlims
xlims_min <- max(c(xlims75[1],xlims50[1],xlims25[1]))
xlims_max <- min(c(xlims75[2],xlims50[2],xlims25[2]))
xlims <- c(xlims_min,xlims_max)

 int_plot <- interactions::interact_plot(chosen_model,
                            pred = !!(x[1]),
                            modx = !!(x[2]),
                            mod2 = !!(x[3]),
                            linearity.check = FALSE,interval = TRUE, int.width = 0.95,
                            modx.values = c(quantile(Train_data_scaled_centred_train[[x[2]]],
                                                     probs = c(0.25,0.50,0.75))),
                            mod2.values = c(quantile(Train_data_scaled_centred_train[[x[3]]],
                                                     probs = c(0.25,0.50,0.75))),
                            plot.points = TRUE,data = Train_data_scaled_centred_train, ... = list(allow.new.levels=TRUE)) + scale_x_continuous(expand = c(0,0)) + coord_cartesian(clip = 'on', ylim = c(0, max(Train_data_scaled_centred_train$stsmolt)),xlim = xlims)
  
 return(int_plot)
})

dirName <- paste0(system.file("vignettes", package = "fishcastr"),"/vignette_figures/FigS5/trout/")
png(file = paste0(dirName,'FigS5g.png'), width=2500, height=4000, res=300)
ggpubr::ggarrange(int_plots[[1]],int_plots[[2]],int_plots[[3]],int_plots[[4]],
          labels = c("Disch","Moon","Temp","Prep"),
          ncol = 1, nrow = 4)
invisible(dev.off())

# -------------------------------------------------------------------------------------------------- #
# without points
int_plots_no_points <- lapply(interactions_list_3,FUN = function(x){
  
    # set x axis lims
  # 75th
  data_75_plus <- Train_data_scaled_centred_train[Train_data_scaled_centred_train[[x[3]]] >= quantile(Train_data_scaled_centred_train[[x[3]]], probs = c((((75+50)/2)/100))),]
xlims75 <- c(range(data_75_plus[[x[1]]]))
  # 50th
  data_50_plus <- Train_data_scaled_centred_train[Train_data_scaled_centred_train[[x[3]]] >= quantile(Train_data_scaled_centred_train[[x[3]]], probs = c((((50+50)/2)/100))),]
xlims50 <- c(range(data_50_plus[[x[1]]]))
  # 75th
  data_25_plus <- Train_data_scaled_centred_train[Train_data_scaled_centred_train[[x[3]]] >= quantile(Train_data_scaled_centred_train[[x[3]]], probs = c((((25+50)/2)/100))),]
xlims25 <- c(range(data_25_plus[[x[1]]]))
# xlims
xlims_min <- max(c(xlims75[1],xlims50[1],xlims25[1]))
xlims_max <- min(c(xlims75[2],xlims50[2],xlims25[2]))
xlims <- c(xlims_min,xlims_max)
  
int_plot <-  interactions::interact_plot(chosen_model,
                            pred = !!(x[1]),
                            modx = !!(x[2]),
                            mod2 = !!(x[3]),
                            linearity.check = FALSE,interval = TRUE, int.width = 0.95,
                            modx.values = c(quantile(Train_data_scaled_centred_train[[x[2]]],
                                                     probs = c(0.25,0.50,0.75))),
                            mod2.values = c(quantile(Train_data_scaled_centred_train[[x[3]]],
                                                     probs = c(0.25,0.50,0.75))),
                            plot.points = FALSE,data = Train_data_scaled_centred_train, ... = list(allow.new.levels=TRUE)) + scale_x_continuous(expand = c(0,0)) + coord_cartesian(xlim = xlims)

# extract auto ylims and change to max count if exceeding it.
if(ggplot_build(int_plot)$layout$panel_scales_y[[1]]$range$range[2] >= max(Train_data_scaled_centred_train$stsmolt)){
int_plot$coordinates$limits$y <- c(0,max(Train_data_scaled_centred_train$stsmolt))
}
return(int_plot)
})

png(file = paste0(dirName,'FigS5h.png'), width=2500, height=4000, res=300)
ggpubr::ggarrange(int_plots_no_points[[1]],int_plots_no_points[[2]],int_plots_no_points[[3]],int_plots_no_points[[4]],
          labels = c("Disch","Moon","Temp","Prep"),
          ncol = 1, nrow = 4)
invisible(dev.off())

 rm(list = ls(all.names = TRUE))
 invisible(gc())
```

## Check plausibility of simulated counts and consistency of predictions with built in glmmTMB simulation

```{r model_trout_counts_II_of_IV_plausible_glmmTMB,eval = FALSE}
# -------------------------------------------------------------------------------------------------- #
# GENERAL PLOTS TO TEST FISHCASTR SIMULATION FUNCTION CONSISTENCY WITH GLMMTMB BUILT IN ----
# -------------------------------------------------------------------------------------------------- #
#object <- m3
library(glmmTMB)
object <- readRDS(paste0(system.file("vignettes",
                                 package = "fishcastr"),
                     "/vignette_data/m3_trout_historic.rds"))

Train_data_scaled_centred_train <- readRDS(paste0(system.file("vignettes",
                                 package = "fishcastr"),
                     "/vignette_data/Train_data_scaled_centred_train.rds"))

new_data <- Train_data_scaled_centred_train

#for checking if long term trend remains in simulations when new levels added (see re.form documentation in glmmTMB)
#new_data$salmonid_year <- Train_data_scaled_centred_train$salmonid_year + 40

# extract conditional mean
cond_mean <- predict(object, newdata=new_data,
                     type="conditional",
                     re.form = NA,
                     allow.new.levels=TRUE, 
                     na.action = na.pass)

# extract dispersion parameter as function of fixed effects, noting log link (hence exp())
f <- formula(object, component = "disp")
X <- model.matrix(f, data = new_data)
beta <- fixef(object)[["disp"]]
eta <- X %*% beta
odp <- c(exp(eta))

# generate random deviates
mu = cond_mean
disp_param = odp

theta <- as.numeric(mu*(1 - (1 - sqrt(1/disp_param))))
lambda <- (1 - sqrt(1/disp_param))
result <- RMKdiscrete::rLGP(n = 1,theta = theta,lambda = lambda)

# check annual sums are reasonably consistent
df_check <- data.frame("result" = result,
                       "salmonid_year" = new_data$salmonid_year,
                       "stsmolt" = new_data$stsmolt)
tapply(df_check$result,INDEX = df_check$salmonid_year,FUN = sum)
tapply(df_check$stsmolt,INDEX = df_check$salmonid_year,FUN = sum)
#par(mfrow = c(1,1))
plot(tapply(df_check$result,INDEX = df_check$salmonid_year,FUN = sum),
     tapply(df_check$stsmolt,INDEX = df_check$salmonid_year,FUN = sum))

#######
# # or if single param poisson zeroinf
# #or if single pram
# zi_prob <- predict(object, newdata=new_data, type="zprob", allow.new.levels=TRUE, na.action = na.pass,re.form = NA)
# 
# cond <- rpois(n = nrow(new_data),
#               lambda = cond_mean)
# 
# result <- ifelse(stats::runif(nrow(new_data))< zi_prob, 0, cond)
# 
#######
 
 mTrain_genpois_op_sims_sqr <- simulate(object,nsim = 1)
# # plot simulations 
 c = 0
 i = 1
      par(mfrow = c(3,1), mar = c(4,4,1,1))
 plot((1+c):(365+c),mTrain_genpois_op_sims_sqr$sim_1[(1+c):(365+c)], type = "s", col = NULL, ylim = c(0,500), main = paste0(i, "glmmtmb"))
 lines((1+c):(365+c),mTrain_genpois_op_sims_sqr$sim_1[(1+c):(365+c)], type = "h", col = "blue")
 plot((1+c):(365+c),result[(1+c):(365+c)], type = "h", col = "green3", main = "manual",ylim = c(0,500))
 plot((1+c):(365+c),Train_data_scaled_centred_train$stsmolt[(1+c):(365+c)], type = "h", col = "red", main = "stsmolt",ylim = c(0,500))
# 
#      for(i in 1:length(unique(df_check$salmonid_year))-1){
#      par(mfrow = c(3,1), mar = c(4,4,1,1))
#  c = 365*i
# plot((1+c):(365+c),mTrain_genpois_op_sims_sqr$sim_1[(1+c):(365+c)], type = "s", col = NULL, ylim = c(0,500), main = paste0(i+1, "glmmtmb"))
# lines((1+c):(365+c),mTrain_genpois_op_sims_sqr$sim_1[(1+c):(365+c)], type = "h", col = "blue")
# plot((1+c):(365+c),result[(1+c):(365+c)], type = "h", col = "green3", main = "manual",ylim = c(0,500))
# plot((1+c):(365+c),Train_data_scaled_centred_train$stsmolt[(1+c):(365+c)], type = "h", col = "red", main = "stsmolt",ylim = c(0,500))
# }
 rm(list = ls(all.names = TRUE))
 invisible(gc())
```
   
## Fit refined model to data using leave-one-year-out approach
   
```{r model_trout_counts_II_of_IV_fit_loo,eval = FALSE}            
# ---------------------------------------------------------------------------------------------------------- #
# LOAD COUNT AND PREDICTOR DATA ----
# ---------------------------------------------------------------------------------------------------------- #
data_stsmolt_enviro_1981_2019 <- readRDS(paste0(system.file("vignettes",
                                                    package = "fishcastr"),
                                               "/vignette_data/data_stsmolt_enviro_1981_2019.rds"))

######################################################################################################
# -------------------------------------------------------------------------------------------------- #
# SUBSET DATA TO 1981 - 2018 TO BUILD MODEL LIST FOR SEASONAL FORECAST LOO VALIDATION ----
# -------------------------------------------------------------------------------------------------- #
data_stsmolt_enviro_1981_2018 <- data_stsmolt_enviro_1981_2019[data_stsmolt_enviro_1981_2019$salmonid_year %in% c(1981:2018),]
all_timeseries_years <- as.list(1981:2018)
suppressMessages(library(glmmTMB))
suppressMessages(library(caret))
suppressMessages(library(plyr))
  suppressMessages(library(parallel))
  suppressMessages(library(doSNOW))
  # n_cores <- 3
  n_cores <- parallel::detectCores() -1
  
  cl <- parallel::makeCluster(n_cores, type = "SOCK")
  
  parallel::clusterSetRNGStream(cl, iseed = 123)
  parallel::clusterCall(cl, function(){ library(glmmTMB)})
  parallel::clusterCall(cl, function(){ library(caret)})
  parallel::clusterCall(cl, function(){ library(plyr)})
  parallel::clusterExport(cl, varlist = c('data_stsmolt_enviro_1981_2018',
                                          'all_timeseries_years'),
                          envir = environment())
  
    doSNOW::registerDoSNOW(cl)

# calibrate models for all years except for year x (i.e., leave-one-year-out
# calibration). This results in models for all years up to 2018. To build
# operational predictions for year 2019, all years PLUS 2018 must be used for
# calibration.
# FOR 1981 - 2018...
system.time({model_list <- plyr::llply(.data = all_timeseries_years, .fun = function(x){
list_x <- do.call(c, all_timeseries_years)
list_minus_x <- list_x[-which(list_x == x)]

# -------------------------------------------------------------------------------------------------- #
# SCALE PREDICTOR VARIABLES IN TRAINING AND TEST DATASETS ----
# -------------------------------------------------------------------------------------------------- #
Train_data <- subset(data_stsmolt_enviro_1981_2018,
                     salmonid_year %in% c(list_minus_x), select = c(date,
                                                                    stsmolt,
                                                                    salmonid_year,
                                                                    ln_migration_prep,
                                                                    salmonid_yday,
                                                                    moonlight_exposure,
                                                                    ln_discharge,
                                                                    Tw_mod))

# Test_data <- subset(data_stsmolt_enviro_1981_2018,
#                     salmonid_year %in% c(x), select = c(date,
#                                                         stsmolt,
#                                                         salmonid_year,
#                                                         ln_migration_prep,
#                                                         salmonid_yday,
#                                                         moonlight_exposure,
#                                                         ln_discharge,
#                                                         Tw_mod))


# SCALE PREDICTORS AND CENTRE THOSE THAT HAVE NON-MEANINGFUL ZEROS (Here, just scale...)
pP_params <- caret::preProcess(Train_data[,4:ncol(Train_data)], method = c("center","scale"))
Train_data_scaled_centred <- predict(object = pP_params, newdata = Train_data)
#Test_data_scaled_centred <- predict(object = pP_params, newdata = Test_data)

# -------------------------------------------------------------------------------------------------- #
# generalised poisson for underdispersion or overdispersion... ----
# -------------------------------------------------------------------------------------------------- #
mTrain_genpois <- glmmTMB::glmmTMB(stsmolt ~ (Tw_mod + I(Tw_mod^2))*(ln_discharge+ln_migration_prep + moonlight_exposure)^2 + (ln_discharge+ln_migration_prep + moonlight_exposure)^3 + (1|salmonid_year),
                          genpois(link = "log"),
                          data=Train_data_scaled_centred,
                          control = glmmTMBControl(parallel = 3))

return(list(mTrain_genpois,pP_params))
}, .progress = 'text', .parallel = TRUE)})

    parallel::stopCluster(cl) # Close all open clusters
# 528.58/60 # 9 mins for 1981-2018 years
 
# -------------------------------------------------------------------------------------------------- #
# EXPORT MODEL AND SCALING FACTOR LIST AS "TWO" rds OBJECTS FOR REDUCING FILE SIZE to less than 100mb for Git Push  ----
# -------------------------------------------------------------------------------------------------- #

# save
model_list_1of2 <- model_list[1:20]
model_list_2of2 <- model_list[21:length(model_list)]

dirName <- paste0(system.file("vignettes", package = "fishcastr"), "/vignette_data/")
saveRDS(model_list_1of2, file = paste0(dirName,"mTrain_genpois_trout_list_1of2.rds"))
saveRDS(model_list_2of2, file = paste0(dirName,"mTrain_genpois_trout_list_2of2.rds"))

# # load
# dirName <- paste0(system.file("vignettes", package = "fishcastr"), "/vignette_data/")
# model_list_1of2 <- readRDS(file = paste0(dirName,"mTrain_genpois_trout_list_1of2.rds"))
# model_list_2of2 <- readRDS(file = paste0(dirName,"mTrain_genpois_trout_list_2of2.rds"))
# model_list <- list()
# model_list[1:length(model_list_1of2)] <- model_list_1of2
# model_list[(1 + length(model_list_1of2)):(length(model_list_1of2)+length(model_list_2of2))] <- model_list_2of2
 rm(list = ls(all.names = TRUE))
 invisible(gc())
```

## Fit refined model structure to all data up to operational year

```{r model_trout_counts_II_of_IV_fit_operational,eval = FALSE}
# ---------------------------------------------------------------------------------------------------------- #
# LOAD COUNT AND PREDICTOR DATA ----
# ---------------------------------------------------------------------------------------------------------- #
data_stsmolt_enviro_1981_2019 <- readRDS(paste0(system.file("vignettes",
                                                    package = "fishcastr"),
                                               "/vignette_data/data_stsmolt_enviro_1981_2019.rds"))

# -------------------------------------------------------------------------------------------------- #
# OPERATIONAL YEAR 2019 (ALL DATA) ----
# -------------------------------------------------------------------------------------------------- #
min_1981 <- min(data_stsmolt_enviro_1981_2019$date[data_stsmolt_enviro_1981_2019$salmonid_year == 1981])
max_2019 <- max(data_stsmolt_enviro_1981_2019$date[data_stsmolt_enviro_1981_2019$salmonid_year == 2018])

Train_data_op <- subset(data_stsmolt_enviro_1981_2019, select = c(date,
                                                                 stsmolt,
                                                                 salmonid_year,
                                                                 ln_migration_prep,
                                                                 salmonid_yday,
                                                                 moonlight_exposure,
                                                                 ln_discharge,
                                                                 Tw_mod),
                        subset = data.table::between(data_stsmolt_enviro_1981_2019$date,
                                                     lower = min_1981,
                                                     upper = max_2019))

# -------------------------------------------------------------------------------------------------- #
# SCALE PREDICTORS AND CENTRE THOSE THAT HAVE NON-MEANINGFUL ZEROS (Here, just scale...) ----
# -------------------------------------------------------------------------------------------------- #
library(caret)
pP_params_op <- caret::preProcess(Train_data_op[,4:ncol(Train_data_op)], method = c("center","scale"))
Train_data_scaled_centred_op <- predict(object = pP_params_op, newdata = Train_data_op)
    
# -------------------------------------------------------------------------------------------------- #
# FIT MODEL ----
# -------------------------------------------------------------------------------------------------- #
library(glmmTMB)
mop <- glmmTMB::glmmTMB(stsmolt ~ (Tw_mod + I(Tw_mod^2))*(ln_discharge+ln_migration_prep + moonlight_exposure)^2 + (ln_discharge+ln_migration_prep + moonlight_exposure)^3 + (1|salmonid_year),
                          genpois(link = "log"),
                          data=Train_data_scaled_centred_op)
simulatedResiduals_genpois <- DHARMa::simulateResiduals(mop)

# -------------------------------------------------------------------------------------------------- #
# MODEL VALIDATION PLOTS FOR OPERATIONAL YEAR (CHECK FOR ISSUES) ------
# -------------------------------------------------------------------------------------------------- #
mod_check <- simulatedResiduals_genpois
# Create vignette sub directories ------------------------------------------------------
dirName <- paste0(system.file("vignettes", package = "fishcastr"),"/vignette_figures/FigS5/trout/op_model/")
dir.create(paste0(dirName), showWarnings = TRUE, mode = "0777")

png(file = paste0(dirName,'FigS5a.png'), width=2100, height=1200, res=300)
plot(mod_check, rank = T, smoothScatter = FALSE, quantreg = TRUE)
invisible(dev.off())

png(file = paste0(dirName,'FigS5b.png'), width=1800, height=2100, res=300)
par(mfrow = c(2,1), oma = c(0,0,0,0), mar = c(4,4,5,4))
# overdispersion
DHARMa::testDispersion(mod_check)
# zero inflation
DHARMa::testZeroInflation(mod_check)
invisible(dev.off())

# -------------------------------------------------------------------------------------------------- #
# NON-LINEARITY VALIDATION PLOTS (IF PATTERNS PRESENT IN FIT VS RESIDUALS) ----
# -------------------------------------------------------------------------------------------------- #
# individual predictors
png(file = paste0(dirName,'FigS5e.png'), width=2500, height=2500, res=300)
par(mfrow = c(2,2), mar = c(3.5,3.5,3.5,0.5),mgp = c(2.5,1,0))
   DHARMa::plotResiduals(form = Train_data_scaled_centred_op$ln_migration_prep,
                         simulationOutput = mod_check,
                         quantreg = T,smoothScatter = FALSE,
                         rank = T, xlab = "ln_migration_prep")
     DHARMa::plotResiduals(form = Train_data_scaled_centred_op$moonlight_exposure,
                         simulationOutput = mod_check,
                         quantreg = T,smoothScatter = FALSE,
                         rank = T, xlab = "moonlight_exposure")
       DHARMa::plotResiduals(form = Train_data_scaled_centred_op$ln_discharge,
                         simulationOutput = mod_check,
                         quantreg = T,smoothScatter = FALSE,
                         rank = T, xlab = "ln_discharge")
              DHARMa::plotResiduals(form = Train_data_scaled_centred_op$Tw_mod,
                         simulationOutput = mod_check,
                         quantreg = T,smoothScatter = FALSE,
                         rank = T, xlab = "Tw_mod")
invisible(dev.off())

# -------------------------------------------------------------------------------------------------- #
# TEMPORAL AUTOCORRELATION ----
# -------------------------------------------------------------------------------------------------- #
temp_autocorr_plot_data <- data.frame("residssim_date" = Train_data_scaled_centred_op$date,
                                      "residssim" = mod_check$scaledResiduals,
                                      "residssim_bioyear" = Train_data_scaled_centred_op$salmonid_year)

# among years ---
png(file = paste0(dirName,'FigS5c.png'), width=2400, height=1400, res=300)
par(mfrow = c(1,1), oma = c(0,0,0,0), mar = c(4,4,5,4))
DHARMa::plotResiduals(mod_check,
                      Train_data_scaled_centred_op$salmonid_year,
                      asFactor = TRUE, main = "S. trutta")
invisible(dev.off())

# within years -----
temp_auto_within_year <- lapply(unique(temp_autocorr_plot_data$residssim_bioyear),FUN = function(x){
DHARMa::testTemporalAutocorrelation(temp_autocorr_plot_data$residssim[temp_autocorr_plot_data$residssim_bioyear == x],
                                    time = temp_autocorr_plot_data$residssim_date[temp_autocorr_plot_data$residssim_bioyear == x], plot = FALSE)
})

png(file = paste0(dirName,'FigS5d.png'), width=2500, height=2000, res=300)
par(mfrow = c(6,7), mar = c(2.5,3.0,0.1,0.1),mgp = c(1.5,0.5,0))
temp_auto_within_year_acf <- lapply(unique(temp_autocorr_plot_data$residssim_bioyear),FUN = function(x){
acf(x = temp_autocorr_plot_data$residssim[temp_autocorr_plot_data$residssim_bioyear == x], cex.axis = 0.75, cex.lab = 0.75)
  mtext(text = paste0(x),side = 3,line = -1.5, cex = 0.75, adj = 0.9)
})
invisible(dev.off())

# -------------------------------------------------------------------------------------------------- #
# INFLUENTIAL YEARS
# see https://cran.r-project.org/web/packages/glmmTMB/vignettes/model_evaluation.pdf
# -------------------------------------------------------------------------------------------------- #
chosen_model <- mop
source(system.file("other_methods","influence_mixed.R", package="glmmTMB"))
system.time(chosen_model_influence <- influence_mixed(chosen_model,
                                                      groups = "salmonid_year",
                                                      component = "cond"))

#595.92 /60# 11 mins

#inf_ind_plot_data <- car::infIndexPlot(chosen_model_influence)# run this first to load libraryd libraries
#cookdist <- cooks.distance(chosen_model_influence)

#cookdist
#png(file = paste0(dirName,'trout/FigS5fm5cook.png'), width=1000, height=10000, res=300)
#inf_ind_plot_data <- car::infIndexPlot(chosen_model_influence)
#invisible(dev.off())
#stats::cooks.distance(infl = chosen_model_influence)
#?cooks.distance
library(car)
inf <- as.data.frame(chosen_model_influence[["fixed.effects[-salmonid_year]"]])
inf_full_mod_eff <-as.list(chosen_model_influence[["fixed.effects"]])
inf <- transform(inf,
                 salmonid_year=rownames(inf),
                 cooks=stats::cooks.distance(chosen_model_influence))
inf$ord <- rank(inf$cooks)

# extract standard errors of param estimates excluding higher levels under investigation
year_names <- names(chosen_model_influence[["vcov[-salmonid_year]"]])
serrs_list <- lapply(year_names,FUN = function(x){
  sqrt(diag(chosen_model_influence[["vcov[-salmonid_year]"]][[x]]))
})
serrs <- do.call(rbind,serrs_list)
rownames(serrs) <- year_names

# calculate dfbetas - each value will be positive if the effect with the included level is stronger than without it.
# e.g., the intercept is greater with the inclusion of 1987 data (because 1987 was a high count)
  dfbetas <- inf
for(i in 1:(ncol(inf)-3)){
  dfbetas[,i] = (inf[,i] - inf_full_mod_eff[[i]])/serrs[,i]
}

#for(i in 1:(ncol(inf)-3)){
#  dfbetas[,i] = (inf[,i] - inf_full_mod_eff[[i]])
#}

dfbetas <- transform(dfbetas,
                     salmonid_year=rownames(dfbetas))

#inf_long_sort <- inf_long[with(inf_long, order(inf_long$variable,-inf_long$ord)),]

library(ggplot2)
theme_set(theme_bw())
png(file = paste0(dirName,'FigS5f.png'), width=7000, height=4000, res=300)
if (require(reshape2)){
  inf_long <- reshape2::melt(dfbetas, id.vars=c("ord","salmonid_year"))
#  inf_long_sort <- inf_long[with(inf_long, order(inf_long$variable,-inf_long$ord)),]
  gg_infl <- (ggplot2::ggplot(inf_long, aes(salmonid_year,value))
              + geom_segment(aes(x=salmonid_year,xend=salmonid_year,y=0,yend=value),colour="black", size = 2)
              + facet_wrap(~variable, scale="free_y")
              + scale_y_continuous(expand=expansion(mult=0.5))
              + geom_text(data=subset(inf_long,
                                       abs(value) > 1),
                           aes(y = value + (0.6 * (value)), label=salmonid_year),
                           vjust=0.0, angle = 90)
              + geom_hline(yintercept=0,linetype = "dashed")
              + theme(axis.text.x = element_text(angle = 90)))
  print(gg_infl)}
invisible(dev.off())

# -------------------------------------------------------------------------------------------------- #
# PLOT ALL TWO AND THREE-WAY INTERACTIONS OF SELECTED MODEL
# -------------------------------------------------------------------------------------------------- #
interactions_list_3 <- list("7" = c("Tw_mod","ln_migration_prep","ln_discharge"),
                          "8" = c("ln_discharge","Tw_mod","moonlight_exposure"),
                          "9" = c("ln_migration_prep","moonlight_exposure","Tw_mod"),
                          "10" = c("moonlight_exposure","ln_discharge","ln_migration_prep"))

# -------------------------------------------------------------------------------------------------- #
# with points
int_plots <- lapply(interactions_list_3,FUN = function(x){
  
  # set x axis lims
  # 75th
  data_75_plus <- Train_data_scaled_centred_op[Train_data_scaled_centred_op[[x[3]]] >= quantile(Train_data_scaled_centred_op[[x[3]]], probs = c((((75+50)/2)/100))),]
xlims75 <- c(range(data_75_plus[[x[1]]]))
  # 50th
  data_50_plus <- Train_data_scaled_centred_op[Train_data_scaled_centred_op[[x[3]]] >= quantile(Train_data_scaled_centred_op[[x[3]]], probs = c((((50+50)/2)/100))),]
xlims50 <- c(range(data_50_plus[[x[1]]]))
  # 75th
  data_25_plus <- Train_data_scaled_centred_op[Train_data_scaled_centred_op[[x[3]]] >= quantile(Train_data_scaled_centred_op[[x[3]]], probs = c((((25+50)/2)/100))),]
xlims25 <- c(range(data_25_plus[[x[1]]]))
# xlims
xlims_min <- max(c(xlims75[1],xlims50[1],xlims25[1]))
xlims_max <- min(c(xlims75[2],xlims50[2],xlims25[2]))
xlims <- c(xlims_min,xlims_max)

 int_plot <- interactions::interact_plot(chosen_model,
                            pred = !!(x[1]),
                            modx = !!(x[2]),
                            mod2 = !!(x[3]),
                            linearity.check = FALSE,interval = TRUE, int.width = 0.95,
                            modx.values = c(quantile(Train_data_scaled_centred_op[[x[2]]],
                                                     probs = c(0.25,0.50,0.75))),
                            mod2.values = c(quantile(Train_data_scaled_centred_op[[x[3]]],
                                                     probs = c(0.25,0.50,0.75))),
                            plot.points = TRUE,data = Train_data_scaled_centred_op) + scale_x_continuous(expand = c(0,0)) + coord_cartesian(clip = 'on', ylim = c(0, max(Train_data_scaled_centred_op$stsmolt)),xlim = xlims)
  
 return(int_plot)
})

png(file = paste0(dirName,'FigS5g.png'), width=2500, height=4000, res=300)
ggpubr::ggarrange(int_plots[[1]],int_plots[[2]],int_plots[[3]],int_plots[[4]],
          labels = c("Disch","Moon","Temp","Prep"),
          ncol = 1, nrow = 4)
invisible(dev.off())

# -------------------------------------------------------------------------------------------------- #
# without points
int_plots_no_points <- lapply(interactions_list_3,FUN = function(x){
  
    # set x axis lims
  # 75th
  data_75_plus <- Train_data_scaled_centred_op[Train_data_scaled_centred_op[[x[3]]] >= quantile(Train_data_scaled_centred_op[[x[3]]], probs = c((((75+50)/2)/100))),]
xlims75 <- c(range(data_75_plus[[x[1]]]))
  # 50th
  data_50_plus <- Train_data_scaled_centred_op[Train_data_scaled_centred_op[[x[3]]] >= quantile(Train_data_scaled_centred_op[[x[3]]], probs = c((((50+50)/2)/100))),]
xlims50 <- c(range(data_50_plus[[x[1]]]))
  # 75th
  data_25_plus <- Train_data_scaled_centred_op[Train_data_scaled_centred_op[[x[3]]] >= quantile(Train_data_scaled_centred_op[[x[3]]], probs = c((((25+50)/2)/100))),]
xlims25 <- c(range(data_25_plus[[x[1]]]))
# xlims
xlims_min <- max(c(xlims75[1],xlims50[1],xlims25[1]))
xlims_max <- min(c(xlims75[2],xlims50[2],xlims25[2]))
xlims <- c(xlims_min,xlims_max)
  
int_plot <-  interactions::interact_plot(chosen_model,
                            pred = !!(x[1]),
                            modx = !!(x[2]),
                            mod2 = !!(x[3]),
                            linearity.check = FALSE,interval = TRUE, int.width = 0.95,
                            modx.values = c(quantile(Train_data_scaled_centred_op[[x[2]]],
                                                     probs = c(0.25,0.50,0.75))),
                            mod2.values = c(quantile(Train_data_scaled_centred_op[[x[3]]],
                                                     probs = c(0.25,0.50,0.75))),
                            plot.points = FALSE,data = Train_data_scaled_centred_op) + scale_x_continuous(expand = c(0,0)) + coord_cartesian(xlim = xlims)

# extract auto ylims and change to max count if exceeding it.
if(ggplot_build(int_plot)$layout$panel_scales_y[[1]]$range$range[2] >= max(Train_data_scaled_centred_op$stsmolt)){
int_plot$coordinates$limits$y <- c(0,max(Train_data_scaled_centred_op$stsmolt))
}
return(int_plot)
})

png(file = paste0(dirName,'FigS5h.png'), width=2500, height=4000, res=300)
ggpubr::ggarrange(int_plots_no_points[[1]],int_plots_no_points[[2]],int_plots_no_points[[3]],int_plots_no_points[[4]],
          labels = c("Disch","Moon","Temp","Prep"),
          ncol = 1, nrow = 4)
invisible(dev.off())

# -------------------------------------------------------------------------------------------------- #
# GENERAL PLOTS TO TEST FISHCASTR SIMULATION FUNCTION CONSISTENCY WITH GLMMTMB BUILT IN ----
# -------------------------------------------------------------------------------------------------- #
object = mop
new_data = Train_data_scaled_centred_op

#for checking if long term trend remains in simulations when new levels added (see re.form documentation in glmmTMB)
#new_data$salmonid_year <- Train_data_scaled_centred_train$salmonid_year + 40

# extract conditional mean
cond_mean <- predict(object, newdata=new_data,
                     type="conditional",
                     re.form = NA,
                     allow.new.levels=TRUE, 
                     na.action = na.pass)

# extract dispersion parameter as function of fixed effects, noting log link (hence exp())
f <- formula(object, component = "disp")
X <- model.matrix(f, data = new_data)
beta <- fixef(object)[["disp"]]
eta <- X %*% beta
odp <- c(exp(eta))

# generate random deviates
mu = cond_mean
disp_param = odp

theta <- as.numeric(mu*(1 - (1 - sqrt(1/disp_param))))
lambda <- (1 - sqrt(1/disp_param))
result <- RMKdiscrete::rLGP(n = 1,theta = theta,lambda = lambda)

# check annual sums are consistent
df_check <- data.frame("result" = result,
                       "salmonid_year" = new_data$salmonid_year,
                       "stsmolt" = new_data$stsmolt)
tapply(df_check$result,INDEX = df_check$salmonid_year,FUN = sum)
tapply(df_check$stsmolt,INDEX = df_check$salmonid_year,FUN = sum)
#par(mfrow = c(1,1))
plot(tapply(df_check$result,INDEX = df_check$salmonid_year,FUN = sum),
     tapply(df_check$stsmolt,INDEX = df_check$salmonid_year,FUN = sum))

#######
# # or if single param poisson zeroinf
# #or if single pram
# zi_prob <- predict(object, newdata=new_data, type="zprob", allow.new.levels=TRUE, na.action = na.pass,re.form = NA)
# 
# cond <- rpois(n = nrow(new_data),
#               lambda = cond_mean)
# 
# result <- ifelse(stats::runif(nrow(new_data))< zi_prob, 0, cond)
# 
#######

#  mTrain_genpois_op_sims_sqr <- simulate(mop,nsim = 1)
# # # plot simulations 
#  c = 0
#  i = 1
#       par(mfrow = c(3,1), mar = c(4,4,1,1))
#  plot((1+c):(365+c),mTrain_genpois_op_sims_sqr$sim_1[(1+c):(365+c)], type = "s", col = NULL, ylim = c(0,500), main = paste0(i, "glmmtmb"))
#  lines((1+c):(365+c),mTrain_genpois_op_sims_sqr$sim_1[(1+c):(365+c)], type = "h", col = "blue")
#  plot((1+c):(365+c),result[(1+c):(365+c)], type = "h", col = "green3", main = "manual",ylim = c(0,500))
#  plot((1+c):(365+c),Train_data_scaled_centred_op$stsmolt[(1+c):(365+c)], type = "h", col = "red", main = "stsmolt",ylim = c(0,500))
# 
#      for(i in 1:length(unique(df_check$salmonid_year))-1){
#      par(mfrow = c(3,1), mar = c(4,4,1,1))
#  c = 365*i
# plot((1+c):(365+c),mTrain_genpois_op_sims_sqr$sim_1[(1+c):(365+c)], type = "s", col = NULL, ylim = c(0,500), main = paste0(i+1, "glmmtmb"))
# lines((1+c):(365+c),mTrain_genpois_op_sims_sqr$sim_1[(1+c):(365+c)], type = "h", col = "blue")
# plot((1+c):(365+c),result[(1+c):(365+c)], type = "h", col = "green3", main = "manual",ylim = c(0,500))
# plot((1+c):(365+c),Train_data_scaled_centred_op$stsmolt[(1+c):(365+c)], type = "h", col = "red", main = "stsmolt",ylim = c(0,500))
# }
              
# -------------------------------------------------------------------------------------------------- #
# EXPORT MOST RECENT MODEL TO RData OBJECT ----
# -------------------------------------------------------------------------------------------------- #

dirName <- paste0(system.file("vignettes", package = "fishcastr"), "/vignette_data/")
saveRDS(mop, file = paste0(dirName,"mTrain_genpois_trout_2019.rds"))

# -------------------------------------------------------------------------------------------------- #
# EXPORT MOST RECENT SCALING FACTORS TO RData OBJECT -----
# -------------------------------------------------------------------------------------------------- #
#dirName <- paste0(system.file("vignettes", package = "fishcastr"), "/vignette_data/")
saveRDS(pP_params_op, file = paste0(dirName,"pP_params_trout_2019.rds"))

rm(list = ls(all.names = TRUE))
invisible(gc())

```
